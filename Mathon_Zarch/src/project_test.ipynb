{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from random import randint\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fillmask = pipeline(\"fill-mask\", model=\"almanach/camembertv2-base\")\n",
    "mask_token = fillmask.tokenizer.mask_token"
   ],
   "id": "e312ff55f674a16a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def augment_data(examples):\n",
    "    outputs = []\n",
    "    for sentence in examples[\"Avis\"]:\n",
    "        words = sentence.split(' ')\n",
    "        K = randint(1, len(words)-1)\n",
    "        masked_sentence = \" \".join(words[:K]  + [mask_token] + words[K+1:])\n",
    "        predictions = fillmask(masked_sentence)\n",
    "        augmented_sequences = [predictions[i][\"sequence\"] for i in range(2)]\n",
    "        outputs += [sentence] + augmented_sequences\n",
    "    return {\"data\": outputs}"
   ],
   "id": "98e3f18328a869b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:34:26.825680Z",
     "start_time": "2025-01-09T00:34:26.630422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_csv(\"../data/ftdataset_train.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
    "df_val = pd.read_csv(\"../data/ftdataset_val.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
    "df_test = pd.read_csv(\"../data/ftdataset_test.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')"
   ],
   "id": "a664131f5445db52",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "modified_data = df_train[df_train[\"Avis\"].apply(len) <= 512][:9]\n",
    "# Conversion en Dataset\n",
    "dataset = Dataset.from_pandas(modified_data)\n",
    "# Application de la fonction augment_data par lots\n",
    "modified_data = dataset.map(augment_data, batched=True, remove_columns=dataset.column_names,batch_size=8)\n",
    "modified_data"
   ],
   "id": "7a0fae24540c4110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(modified_data[\"data\"]))\n",
    "[df_train.Ambiance.value_counts(),\n",
    "df_train.Cuisine.value_counts(),\n",
    "df_train.Prix.value_counts(),\n",
    "df_train.Service.value_counts()]"
   ],
   "id": "f8c92758147bdde8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "modified_data_512 = df_train[df_train[\"Avis\"].apply(len) > 1024][:9]",
   "id": "1c346b488bc0d67b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"almanach/camembertv2-base\")\n",
    "dataset_512 = Dataset.from_pandas(modified_data_512)\n",
    "sequences = [dataset_512[\"Avis\"][0]]\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "batch[\"labels\"] = torch.tensor([1, 1])\n",
    "dataset_512.features"
   ],
   "id": "1da6e9b4240fbd1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:34:32.447278Z",
     "start_time": "2025-01-09T00:34:31.293029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, ClassLabel\n",
    "# Convertir le DataFrame en Dataset\n",
    "dataset = {}\n",
    "dataset[\"train\"] = Dataset.from_pandas(df_train)\n",
    "dataset[\"test\"] = Dataset.from_pandas(df_test)\n",
    "\n",
    "# Fonction de transformation pour convertir les colonnes en ClassLabel\n",
    "# Définir les étiquettes de classe pour chaque colonne\n",
    "labels = [\"Négative\", \"Neutre\", \"Positive\", \"NE\"]\n",
    "class_label = ClassLabel(names=labels)\n",
    "\n",
    "# Fonction de transformation pour convertir les colonnes en ClassLabel\n",
    "def transform_labels(example):\n",
    "    example[\"Prix\"] = class_label.encode_example(str(example[\"Prix\"]))\n",
    "    example[\"Cuisine\"] = class_label.encode_example(str(example[\"Cuisine\"]))\n",
    "    example[\"Service\"] = class_label.encode_example(str(example[\"Service\"]))\n",
    "    example[\"Ambiance\"] = class_label.encode_example(str(example[\"Ambiance\"]))\n",
    "    return example\n",
    "# Appliquer la transformation au dataset test\n",
    "dataset[\"train\"] = dataset[\"train\"].map(transform_labels)\n",
    "dataset[\"test\"] = dataset[\"test\"].map(transform_labels)"
   ],
   "id": "b492515d5b502f27",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4471/4471 [00:00<00:00, 5087.96 examples/s]\n",
      "Map: 100%|██████████| 902/902 [00:00<00:00, 5100.72 examples/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:19:15.451014Z",
     "start_time": "2025-01-04T18:19:15.384440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Afficher le dataset transformé\n",
    "print(dataset[\"train\"][\"labels\"][0])\n",
    "print(dataset[\"train\"][\"Prix\"][0], dataset[\"train\"][\"Cuisine\"][0], dataset[\"train\"][\"Service\"][0], dataset[\"train\"][\"Ambiance\"][0])"
   ],
   "id": "e76e3309280568e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2]\n",
      "Positive Positive Positive Positive\n"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:19:44.716960Z",
     "start_time": "2025-01-04T18:19:44.709433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = [\"Négative\", \"Neutre\", \"Positive\", \"NE\"]\n",
    "class2id = {class_:id for id, class_ in enumerate(classes)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}\n",
    "print(classes)\n",
    "print(class2id)\n",
    "print(id2class)"
   ],
   "id": "e28eea2f07d532f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Négative', 'Neutre', 'Positive', 'NE']\n",
      "{'Négative': 0, 'Neutre': 1, 'Positive': 2, 'NE': 3}\n",
      "{0: 'Négative', 1: 'Neutre', 2: 'Positive', 3: 'NE'}\n"
     ]
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:33:35.044868Z",
     "start_time": "2025-01-04T18:33:30.252369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "def preprocess_function(example):\n",
    "    return tokenizer(example[\"Avis\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = {}\n",
    "tokenized_dataset[\"train\"] = dataset[\"train\"].map(preprocess_function)\n",
    "tokenized_dataset[\"test\"] = dataset[\"test\"].map(preprocess_function)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator"
   ],
   "id": "1c236d2ec0ad5129",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4471/4471 [00:03<00:00, 1129.06 examples/s]\n",
      "Map: 100%|██████████| 902/902 [00:00<00:00, 1137.98 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=RobertaTokenizerFast(name_or_path='almanach/camembertv2-base', vocab_size=32768, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:33:03.906754Z",
     "start_time": "2025-01-04T18:33:03.606287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"almanach/camembertv2-base\", num_labels=len(classes),id2label=id2class, label2id=class2id,problem_type = \"multi_label_classification\")\n",
    "\n",
    "tokenized_dataset"
   ],
   "id": "b36620d78c99d2f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at almanach/camembertv2-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['NomDuGroupe', 'Restaurant', 'Note', 'Prix', 'Cuisine', 'Service', 'Ambiance', 'Avis', 'URL', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 4471\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['NomDuGroupe', 'Restaurant', 'Note', 'Prix', 'Cuisine', 'Service', 'Ambiance', 'Avis', 'URL', 'labels', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 902\n",
       " })}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:33:35.063062Z",
     "start_time": "2025-01-04T18:33:35.052395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].remove_columns([\"Restaurant\",\"Avis\", \"Prix\", \"Cuisine\", \"Service\", \"Ambiance\",\"NomDuGroupe\",\"Note\",\"URL\"])\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].remove_columns([\"Restaurant\",\"Avis\", \"Prix\", \"Cuisine\", \"Service\", \"Ambiance\",\"NomDuGroupe\",\"Note\",\"URL\"])\n",
    "tokenized_dataset[\"train\"].set_format(\"torch\")\n",
    "tokenized_dataset[\"test\"].set_format(\"torch\")"
   ],
   "id": "290c9c947e1d28a6",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:52:27.729828Z",
     "start_time": "2025-01-09T00:52:27.703986Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_dataset",
   "id": "25401c9aebd198c0",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m tokenized_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mdescribe()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tokenized_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:33:39.482949Z",
     "start_time": "2025-01-04T18:33:39.476600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ],
   "id": "d9a6656f201e3c78",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:33:42.395078Z",
     "start_time": "2025-01-04T18:33:42.381081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ],
   "id": "27e5c21d4d081bd9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([8, 4]),\n",
       " 'input_ids': torch.Size([8, 113]),\n",
       " 'attention_mask': torch.Size([8, 113])}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:39:17.365245Z",
     "start_time": "2025-01-04T18:39:17.356772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ],
   "id": "9691cf2aa032db8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677\n"
     ]
    }
   ],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:39:28.768173Z",
     "start_time": "2025-01-04T18:39:28.755168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ],
   "id": "b06b32558a4c101f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T18:39:39.672129Z",
     "start_time": "2025-01-04T18:39:36.613817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ],
   "id": "e347a71491a9333a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1677 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[202], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_dataloader:\n\u001B[0;32m      8\u001B[0m     batch \u001B[38;5;241m=\u001B[39m {k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatch)\n\u001B[0;32m     10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mloss\n\u001B[0;32m     11\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ft\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ft\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ft\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1355\u001B[0m, in \u001B[0;36mRobertaForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1353\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mproblem_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_label_classification\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1354\u001B[0m         loss_fct \u001B[38;5;241m=\u001B[39m BCEWithLogitsLoss()\n\u001B[1;32m-> 1355\u001B[0m         loss \u001B[38;5;241m=\u001B[39m loss_fct(logits, labels)\n\u001B[0;32m   1357\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[0;32m   1358\u001B[0m     output \u001B[38;5;241m=\u001B[39m (logits,) \u001B[38;5;241m+\u001B[39m outputs[\u001B[38;5;241m2\u001B[39m:]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ft\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ft\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ft\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:734\u001B[0m, in \u001B[0;36mBCEWithLogitsLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mbinary_cross_entropy_with_logits(\u001B[38;5;28minput\u001B[39m, target,\n\u001B[0;32m    735\u001B[0m                                               \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight,\n\u001B[0;32m    736\u001B[0m                                               pos_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_weight,\n\u001B[0;32m    737\u001B[0m                                               reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ft\\Lib\\site-packages\\torch\\nn\\functional.py:3244\u001B[0m, in \u001B[0;36mbinary_cross_entropy_with_logits\u001B[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001B[0m\n\u001B[0;32m   3241\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (target\u001B[38;5;241m.\u001B[39msize() \u001B[38;5;241m==\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize()):\n\u001B[0;32m   3242\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget size (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39msize()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) must be the same as input size (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 3244\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mbinary_cross_entropy_with_logits(\u001B[38;5;28minput\u001B[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:55:37.894010Z",
     "start_time": "2025-01-09T00:55:36.629638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datasets import Dataset, ClassLabel\n",
    "\n",
    "# Charger le dataset\n",
    "df_train = pd.read_csv(\"../data/ftdataset_train.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
    "df_test = pd.read_csv(\"../data/ftdataset_test.tsv\", sep=' *\\t *', encoding='utf-8', engine='python')\n",
    "\n",
    "# Convertir le DataFrame en Dataset\n",
    "dataset = {}\n",
    "dataset[\"train\"] = Dataset.from_pandas(df_train)\n",
    "dataset[\"test\"] = Dataset.from_pandas(df_test)\n",
    "\n",
    "\n",
    "\n",
    "# Appliquer la transformation au dataset\n",
    "dataset[\"train\"] = dataset[\"train\"].map(transform_labels)\n",
    "dataset[\"test\"] = dataset[\"test\"].map(transform_labels)\n",
    "\n",
    "# Afficher le dataset transformé\n",
    "print(dataset[\"train\"][\"Prix\"][0], dataset[\"train\"][\"Cuisine\"][0], dataset[\"train\"][\"Service\"][0],dataset[\"train\"][\"Ambiance\"][0])"
   ],
   "id": "d86dc81b716bbea9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4471/4471 [00:00<00:00, 5244.56 examples/s]\n",
      "Map: 100%|██████████| 902/902 [00:00<00:00, 5260.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 2 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:59:15.074840Z",
     "start_time": "2025-01-09T00:59:15.038417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convertir le Dataset en DataFrame pour calculer les moyennes\n",
    "df_transformed = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Calculer les moyennes des colonnes spécifiées\n",
    "moyennes = df_transformed[['Prix', 'Cuisine', 'Ambiance', 'Service']].describe()\n",
    "nombre_de_uns = (df_transformed[['Prix', 'Cuisine', 'Ambiance', 'Service']] == 1).sum()\n",
    "nombre_de_deux = (df_transformed[['Prix', 'Cuisine', 'Ambiance', 'Service']] == 2).sum()\n",
    "nombre_de_trois = (df_transformed[['Prix', 'Cuisine', 'Ambiance', 'Service']] == 3).sum()\n",
    "nombre_de_zero = (df_transformed[['Prix', 'Cuisine', 'Ambiance', 'Service']] == 0).sum()\n",
    "# Afficher les moyennes\n",
    "print(moyennes)"
   ],
   "id": "569ffb225701ff80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Prix      Cuisine     Ambiance      Service\n",
      "count  4471.000000  4471.000000  4471.000000  4471.000000\n",
      "mean      2.362335     1.739432     2.242899     1.828450\n",
      "std       1.039598     0.798130     0.925915     0.927027\n",
      "min       0.000000     0.000000     0.000000     0.000000\n",
      "25%       2.000000     2.000000     2.000000     2.000000\n",
      "50%       3.000000     2.000000     2.000000     2.000000\n",
      "75%       3.000000     2.000000     3.000000     2.000000\n",
      "max       3.000000     3.000000     3.000000     3.000000\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
